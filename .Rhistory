jarque.bera.test(ci1)
ca.jo.re<- ca.jo(etf.dat[1000:4000, 1:10])
w_true<- ca.jo.re@V[,1]
summary(ca.jo.re)
ci1<- data.matrix(etf.dat[, 1:10]) %*%  as.numeric(ca.jo.re@ V[,1])
plot.ts(ci1)
ca.jo.re<- ca.jo(etf.dat[1000:2000, 1:10])
w_true<- ca.jo.re@V[,1]
summary(ca.jo.re)
ci1<- data.matrix(etf.dat[, 1:10]) %*%  as.numeric(ca.jo.re@ V[,1])
plot.ts(ci1)
jarque.bera.test(ci1)
ca.jo.re<- ca.jo(etf.dat[1000:2000, 1:10])
w_true<- ca.jo.re@V[,1]
summary(ca.jo.re)
ci1<- data.matrix(etf.dat[, 1:10]) %*%  as.numeric(ca.jo.re@ V[,1])
plot.ts(ci1)
jarque.bera.test(ci1)
summary(ur.df(ci1, lags= 3))
ca.jo.re<- ca.jo(etf.dat[1000:3000, 1:10])
w_true<- ca.jo.re@V[,1]
summary(ca.jo.re)
ci1<- data.matrix(etf.dat[, 1:10]) %*%  as.numeric(ca.jo.re@ V[,1])
plot.ts(ci1)
jarque.bera.test(ci1)
rm(list= ls())
library(IKTrading)
library(quantstrat)
library(Quandl)
library(tseries)
library(urca)
library(Quandl)
qdKey<- 'iz3gpGtYiTWsRDWdgpaD'
startDate<- '2003-01-11'
endDate<- '2015-12-31'
mkt.dat<- Quandl(c('YAHOO/INDEX_SPY.4',
#'GOOG/AMEX_TLT.4',
#'GOOG/AMEX_VOX.4',
#'GOOG/AMEX_VGT.4',
'YAHOO/XLI.4',
'YAHOO/XLE.4',
'YAHOO/XLU.4',
'YAHOO/XLP.4',
'YAHOO/XLV.4',
'YAHOO/XLB.4',
'YAHOO/XLY.4',
'YAHOO/XLF.4',
'YAHOO/XLK.4'
# 'CHRIS/CBOE_VX1.4',
# 'CHRIS/CBOE_VX2.4',
# 'CHRIS/CBOE_VX3.4',
# 'CHRIS/CBOE_VX4.4',
# 'CHRIS/CBOE_VX5.4',
# 'YAHOO/INDEX_GSPC.4',
# 'ML/HYOAS',
# 'CBOE/SKEW'
),
start_date= startDate,
end_date= endDate,
collapse = 'daily',
api_key= qdKey)
colnames(mkt.dat)<- c('date',
'SPY',
# 'TLT',
# 'VOX',
# 'VGT',
'XLI',
'XLE',
'XLU',
'XLP',
'XLV',
'XLB',
'XLY',
'XLF',
'XLK'
# 'VX1',
# 'VX2',
# 'VX3',
# 'VX4',
# 'VX5',
# 'SP',
# 'HYS',
# 'SKEW'
)
mkt.dat<- zoo(mkt.dat[, 2: dim(mkt.dat)[2]], order.by = mkt.dat$date)
mkt.dat<- na.remove(mkt.dat)
etf.dat<- mkt.dat[, c(
'SPY',
# 'TLT',
# 'VOX',
# 'VGT',
'XLI',
'XLE',
'XLU',
'XLP',
'XLV',
'XLB',
'XLY',
'XLF',
'XLK')]
# TLT data stops at 2016 -02- 01
weight.generation<- function ( priceData, burnRows=1000,
window= 1000, est_interval= 60){
# weight.generation computes the cointegration vector
# input:
# priceData: the time series data containing the price of all products,
# indexed by date
# output:
# zoo obj, the normalized cointegration vector,
# The flag column indicates whether this cointegration vector is valid.
N<- dim(priceData)[1]
M<- dim(priceData)[2]
weight<- data.frame(matrix(NA, nrow = N, ncol = M))
colnames(weight)<- c(colnames(priceData))
tmp1<- data.frame(matrix(NA, nrow = N, ncol=1))
colnames(tmp1)<- 'flag'
tmp2<- data.frame(matrix(NA, nrow = N, ncol = 1))
colnames(tmp2)<- 'reEst_count'
j<-1
for (i in seq(burnRows, N, by = est_interval )) {
dat<- priceData[1: i, ]
dat<- tail(dat, window)
ca.jo.result<- ca.jo(x = dat)
# print(summary(ca.jo.result))
flag<- tail(as.numeric(ca.jo.result@cval),1)<
tail(as.numeric(ca.jo.result@teststat), 1)
#print(flag)
w<- ca.jo.result@V[, 1]
weight[i,]<- as.numeric(w)
#print(weight[i,])
#print(as.numeric(w))
tmp1[i,]<- flag
tmp2[i,]<- j
j<- j+1
}
weight<- na.locf(weight, na.rm = F)
tmp1<- na.locf(tmp1, na.rm = F)
tmp2<- na.locf(tmp2, na.rm = F)
weight<- zoo(cbind(as.matrix(weight), as.matrix(tmp1), as.matrix(tmp2)),
order.by = index(priceData))
return (weight)
}
W<- weight.generation(etf.dat, est_interval =  15, burnRows =  2000, window = 1800)
##
tmp<- merge(etf.dat, W)
tmp<- na.remove(tmp)
A<- as.matrix(tmp)[,1:10]
B<- as.matrix(tmp)[,11:20]
ci<- rowSums(A*B)
plot.ts(ci)
##
ca.jo.re<- ca.jo(etf.dat[, 1:10])
w_true<- ca.jo.re@V[,1]
summary(ca.jo.re)
ci1<- data.matrix(etf.dat[, 1:10]) %*%  as.numeric(ca.jo.re@ V[,1])
plot.ts(ci1)
jarque.bera.test(ci1)
summary(ur.df(ci1, lags= 3))
ca.jo.re<- ca.jo(etf.dat[, 2:10])
w_true<- ca.jo.re@V[,1]
summary(ca.jo.re)
ci1<- data.matrix(etf.dat[, 1:10]) %*%  as.numeric(ca.jo.re@ V[,1])
plot.ts(ci1)
jarque.bera.test(ci1)
ca.jo.re<- ca.jo(etf.dat[, 2:10])
w_true<- ca.jo.re@V[,1]
summary(ca.jo.re)
ci1<- data.matrix(etf.dat[, 2:10]) %*%  as.numeric(ca.jo.re@ V[,1])
plot.ts(ci1)
jarque.bera.test(ci1)
summary(ur.df(ci1, lags= 3))
library(tseries)
library(forecast)
auto.arima(ci1)
acf(ci1)
acf(resid(auto.arima(ci1)))
install.packages(c("car", "caret", "curl", "DBI", "digest", "dynlm", "htmlwidgets", "knitr", "maps", "RcppArmadillo", "repr", "tidyr"))
install.packages("randomForest")
library(randomForest)
rfNews()
data("iris")
iris
library(randomForest)
data("iris")
iris.rf<- randomForest(formula= Species~,  data= iris,
importance= T, proximity= T, ntree= 5000, varImpPlot= T)
? randomForest
library(randomForest)
data("iris")
iris.rf<- randomForest(formula= Species~ ,  data= iris,
importance= T, proximity= T, ntree= 5000, varImpPlot= T)
library(randomForest)
data("iris")
iris.rf<- randomForest(formula= Species~. ,  data= iris,
importance= T, proximity= T, ntree= 5000, varImpPlot= T)
summary(iris.rf)
print(iris.rf)
varImpPlot(iris.rf)
? MDSplot
MDSplot(iris.rf, fac = iris$Species, palette = c(1,2))
MDSplot(iris.rf, fac = iris$Species, palette = c(1,2,3))
MDSplot(iris.rf, fac = iris$Species, palette = c(1,2,3,4))
MDSplot(iris.rf, fac = iris$Species, palette = c('red', 'green', 'blue'))
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("xgboost", repos="http://dmlc.ml/drat/", type = "source")
library(xgboost)
? xgboost
gl(2,7)
gl(2,3)
gl(2,3)
gl(2,3)
gl(2,3)
gl(28)
gl(2, 6)
dd <- data.frame(a = gl(3,4), b = gl(4,1,12))# balanced 2-way
options("contrasts") # the default
library(Matrix)
sparse.model.matrix(~a+b, data = dd)
dd
sparse.model.matrix(a~. data = dd)
sparse.model.matrix(a~. ,data = dd)
install.packages(c("gss", "Matrix", "mgcv", "quantmod", "quantreg", "R6", "RcppArmadillo", "RcppEigen", "stringr", "tibble"))
install.packages("xgboost")
dd <- data.frame(a = gl(3,4), b = gl(4,1,12))# balanced 2-way
options("contrasts") # the default:  "contr.treatment"
sparse.model.matrix(~ a + b, dd)
dd
library(Matrix
)
dd <- data.frame(a = gl(3,4), b = gl(4,1,12))# balanced 2-way
options("contrasts") # the default:  "contr.treatment"
sparse.model.matrix(~ a + b, dd)
sparse.model.matrix(a~. , dd)
qdKey<- 'iz3gpGtYiTWsRDWdgpaD'
rm(list= ls())
library(IKTrading)
library(quantstrat)
library(Quandl)
library(tseries)
library(urca)
library(Quandl)
qdKey<- 'iz3gpGtYiTWsRDWdgpaD'
startDate<- '2003-01-11'
endDate<- '2015-12-31'
mkt.dat<- Quandl(c('YAHOO/INDEX_SPY.4',
#'GOOG/AMEX_TLT.4',
#'GOOG/AMEX_VOX.4',
#'GOOG/AMEX_VGT.4',
'YAHOO/XLI.4',
'YAHOO/XLE.4',
'YAHOO/XLU.4',
'YAHOO/XLP.4',
'YAHOO/XLV.4',
'YAHOO/XLB.4',
'YAHOO/XLY.4',
'YAHOO/XLF.4',
'YAHOO/XLK.4'
# 'CHRIS/CBOE_VX1.4',
# 'CHRIS/CBOE_VX2.4',
# 'CHRIS/CBOE_VX3.4',
# 'CHRIS/CBOE_VX4.4',
# 'CHRIS/CBOE_VX5.4',
# 'YAHOO/INDEX_GSPC.4',
# 'ML/HYOAS',
# 'CBOE/SKEW'
),
start_date= startDate,
end_date= endDate,
collapse = 'daily',
api_key= qdKey)
colnames(mkt.dat)<- c('date',
'SPY',
# 'TLT',
# 'VOX',
# 'VGT',
'XLI',
'XLE',
'XLU',
'XLP',
'XLV',
'XLB',
'XLY',
'XLF',
'XLK'
# 'VX1',
# 'VX2',
# 'VX3',
# 'VX4',
# 'VX5',
# 'SP',
# 'HYS',
# 'SKEW'
)
mkt.dat<- zoo(mkt.dat[, 2: dim(mkt.dat)[2]], order.by = mkt.dat$date)
mkt.dat<- na.remove(mkt.dat)
etf.dat<- mkt.dat[, c(
'SPY',
# 'TLT',
# 'VOX',
# 'VGT',
'XLI',
'XLE',
'XLU',
'XLP',
'XLV',
'XLB',
'XLY',
'XLF',
'XLK')]
# TLT data stops at 2016 -02- 01
weight.generation<- function ( priceData, burnRows=1000,
window= 1000, est_interval= 60){
# weight.generation computes the cointegration vector
# input:
# priceData: the time series data containing the price of all products,
# indexed by date
# output:
# zoo obj, the normalized cointegration vector,
# The flag column indicates whether this cointegration vector is valid.
N<- dim(priceData)[1]
M<- dim(priceData)[2]
weight<- data.frame(matrix(NA, nrow = N, ncol = M))
colnames(weight)<- c(colnames(priceData))
tmp1<- data.frame(matrix(NA, nrow = N, ncol=1))
colnames(tmp1)<- 'flag'
tmp2<- data.frame(matrix(NA, nrow = N, ncol = 1))
colnames(tmp2)<- 'reEst_count'
j<-1
for (i in seq(burnRows, N, by = est_interval )) {
dat<- priceData[1: i, ]
dat<- tail(dat, window)
ca.jo.result<- ca.jo(x = dat)
# print(summary(ca.jo.result))
flag<- tail(as.numeric(ca.jo.result@cval),1)<
tail(as.numeric(ca.jo.result@teststat), 1)
#print(flag)
w<- ca.jo.result@V[, 1]
weight[i,]<- as.numeric(w)
#print(weight[i,])
#print(as.numeric(w))
tmp1[i,]<- flag
tmp2[i,]<- j
j<- j+1
}
weight<- na.locf(weight, na.rm = F)
tmp1<- na.locf(tmp1, na.rm = F)
tmp2<- na.locf(tmp2, na.rm = F)
weight<- zoo(cbind(as.matrix(weight), as.matrix(tmp1), as.matrix(tmp2)),
order.by = index(priceData))
return (weight)
}
W<- weight.generation(etf.dat, est_interval =  15, burnRows =  2000, window = 1800)
##
tmp<- merge(etf.dat, W)
tmp<- na.remove(tmp)
A<- as.matrix(tmp)[,1:10]
B<- as.matrix(tmp)[,11:20]
ci<- rowSums(A*B)
plot.ts(ci)
##
ca.jo.re<- ca.jo(etf.dat[, 2:10])
w_true<- ca.jo.re@V[,1]
summary(ca.jo.re)
ci1<- data.matrix(etf.dat[, 2:10]) %*%  as.numeric(ca.jo.re@ V[,1])
plot.ts(ci1)
jarque.bera.test(ci1)
summary(ur.df(ci1, lags= 3))
library(forecast)
auto.arima(ci1)
acf(ci1)
acf(resid(auto.arima(ci1)))
install.packages(c("curl", "DBI", "forecast", "foreign", "jsonlite", "lattice", "mgcv", "Rcpp", "shiny", "SparseM", "stabledist", "urca"))
install.packages(c("curl", "DBI", "forecast", "foreign", "jsonlite",
install.packages(c("curl", "DBI", "forecast", "foreign", "jsonlite", "lattice", "mgcv", "Rcpp", "shiny", "SparseM", "stabledist", "urca"))
install.packages(c("curl", "DBI", "forecast", "foreign", "jsonlite",
install.packages(c("curl", "DBI", "forecast", "foreign", "jsonlite", "lattice", "mgcv", "Rcpp", "shiny", "SparseM", "stabledist", "urca"))
rm(list= ls())
library(IKTrading)
library(quantstrat)
library(Quandl)
library(tseries)
library(urca)
library(Quandl)
qdKey<- 'iz3gpGtYiTWsRDWdgpaD'
startDate<- '2003-01-11'
endDate<- '2015-12-31'
mkt.dat<- Quandl(c('YAHOO/INDEX_SPY.4',
#'GOOG/AMEX_TLT.4',
#'GOOG/AMEX_VOX.4',
#'GOOG/AMEX_VGT.4',
'YAHOO/XLI.4',
'YAHOO/XLE.4',
'YAHOO/XLU.4',
'YAHOO/XLP.4',
'YAHOO/XLV.4',
'YAHOO/XLB.4',
'YAHOO/XLY.4',
'YAHOO/XLF.4',
'YAHOO/XLK.4'
# 'CHRIS/CBOE_VX1.4',
# 'CHRIS/CBOE_VX2.4',
# 'CHRIS/CBOE_VX3.4',
# 'CHRIS/CBOE_VX4.4',
# 'CHRIS/CBOE_VX5.4',
# 'YAHOO/INDEX_GSPC.4',
# 'ML/HYOAS',
# 'CBOE/SKEW'
),
start_date= startDate,
end_date= endDate,
collapse = 'daily',
api_key= qdKey)
colnames(mkt.dat)<- c('date',
'SPY',
# 'TLT',
# 'VOX',
# 'VGT',
'XLI',
'XLE',
'XLU',
'XLP',
'XLV',
'XLB',
'XLY',
'XLF',
'XLK'
# 'VX1',
# 'VX2',
# 'VX3',
# 'VX4',
# 'VX5',
# 'SP',
# 'HYS',
# 'SKEW'
)
mkt.dat<- zoo(mkt.dat[, 2: dim(mkt.dat)[2]], order.by = mkt.dat$date)
mkt.dat<- na.remove(mkt.dat)
etf.dat<- mkt.dat[, c(
'SPY',
# 'TLT',
# 'VOX',
# 'VGT',
'XLI',
'XLE',
'XLU',
'XLP',
'XLV',
'XLB',
'XLY',
'XLF',
'XLK')]
# TLT data stops at 2016 -02- 01
weight.generation<- function ( priceData, burnRows=1000,
window= 1000, est_interval= 60){
# weight.generation computes the cointegration vector
# input:
# priceData: the time series data containing the price of all products,
# indexed by date
# output:
# zoo obj, the normalized cointegration vector,
# The flag column indicates whether this cointegration vector is valid.
N<- dim(priceData)[1]
M<- dim(priceData)[2]
weight<- data.frame(matrix(NA, nrow = N, ncol = M))
colnames(weight)<- c(colnames(priceData))
tmp1<- data.frame(matrix(NA, nrow = N, ncol=1))
colnames(tmp1)<- 'flag'
tmp2<- data.frame(matrix(NA, nrow = N, ncol = 1))
colnames(tmp2)<- 'reEst_count'
j<-1
for (i in seq(burnRows, N, by = est_interval )) {
dat<- priceData[1: i, ]
dat<- tail(dat, window)
ca.jo.result<- ca.jo(x = dat)
# print(summary(ca.jo.result))
flag<- tail(as.numeric(ca.jo.result@cval),1)<
tail(as.numeric(ca.jo.result@teststat), 1)
#print(flag)
w<- ca.jo.result@V[, 1]
weight[i,]<- as.numeric(w)
#print(weight[i,])
#print(as.numeric(w))
tmp1[i,]<- flag
tmp2[i,]<- j
j<- j+1
}
weight<- na.locf(weight, na.rm = F)
tmp1<- na.locf(tmp1, na.rm = F)
tmp2<- na.locf(tmp2, na.rm = F)
weight<- zoo(cbind(as.matrix(weight), as.matrix(tmp1), as.matrix(tmp2)),
order.by = index(priceData))
return (weight)
}
W<- weight.generation(etf.dat, est_interval =  15, burnRows =  2000, window = 1800)
##
tmp<- merge(etf.dat, W)
tmp<- na.remove(tmp)
A<- as.matrix(tmp)[,1:10]
B<- as.matrix(tmp)[,11:20]
ci<- rowSums(A*B)
plot.ts(ci)
ca.jo.re<- ca.jo(etf.dat[, 2:10])
w_true<- ca.jo.re@V[,1]
summary(ca.jo.re)
setwd('/Users/Eric/Documents/Vol_prediction')
load('egarch_model')
egarch_model$MSE/ var(egarch_model$roll.pred$realized_vol)
load('rf')
sqrt(rf$MSE)/ std(rf$roll.pred$reallized_vol)
sqrt(rf$MSE)/ sqrt(var(rf$roll.pred$reallized_vol))
rf$MSE/ var( rf$roll.pred$reallized_vol)
